name: Daily Log Anomaly Analysis

on:
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * *' 

permissions:
  models: read
  contents: read

jobs:
  analyze-logs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Analyze logs for anomalies
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Use Python to properly handle log content and create JSON request
          python3 -c "
          import json
          import string
          import sys
          
          try:
              # Read the log content and handle any encoding issues
              with open('logs/app.log', 'r', encoding='utf-8', errors='replace') as f:
                  log_content = f.read()
              
              # Clean the log content to remove any problematic control characters
              # Keep only printable characters and common whitespace
              printable_chars = string.printable
              cleaned_content = ''.join(char if char in printable_chars else ' ' for char in log_content)
              
              # Create the API request
              request_data = {
                  'messages': [
                      {
                          'role': 'user',
                          'content': 'You are a log analysis expert. Analyze this application log file and provide a comprehensive report. Please identify and categorize any anomalies, security incidents, performance issues, and operational problems. Structure your response with clear sections for: 1) Executive Summary, 2) Security Incidents, 3) System Performance Issues, 4) Operational Problems, 5) Log Format Anomalies, 6) Recommendations. Here is the log content:\\n\\n' + cleaned_content
                      }
                  ],
                  'model': 'openai/gpt-4o'
              }
              
              # Write the properly formatted JSON request
              with open('/tmp/final_request.json', 'w') as f:
                  json.dump(request_data, f)
              
              print('API request prepared successfully')
          
          except Exception as e:
              print(f'Error preparing request: {e}')
              sys.exit(1)
          "
          
          # Call AI model to analyze logs
          RESPONSE=$(curl -s "https://models.github.ai/inference/chat/completions" \
             -H "Content-Type: application/json" \
             -H "Authorization: Bearer $GITHUB_TOKEN" \
             -d @/tmp/final_request.json)
          
          echo "=== 📊 COMPREHENSIVE LOG ANALYSIS REPORT ==="
          echo "Generated on: $(date)"
          echo "Log file: logs/app.log"
          echo "Analysis powered by: GitHub Models (GPT-4o)"
          echo "=================================="
          echo ""
          
          # Capture the analysis results
          ANALYSIS_OUTPUT=$(echo "$RESPONSE" | python3 -c "
          import sys, json
          try:
              data = json.load(sys.stdin)
              if 'choices' in data and len(data['choices']) > 0:
                  print(data['choices'][0]['message']['content'])
              else:
                  print('❌ Error: Unexpected response format')
          except Exception as e:
              print('❌ Error processing response:', str(e))
          ")
          
          # Display the results
          echo "$ANALYSIS_OUTPUT"
          
          # Create GitHub Job Summary
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # 📊 Log Analysis Report
          
          **Generated:** $(date)  
          **Repository:** ${{ github.repository }}  
          **Log File:** `logs/app.log`  
          **Analysis Model:** GitHub Models (GPT-4o)
          
          ## 📈 Log Statistics
          - **Total lines:** $(wc -l < logs/app.log)
          - **File size:** $(du -h logs/app.log | cut -f1)
          - **ERROR entries:** $(grep -c '\[ERROR\]' logs/app.log || echo '0')
          - **WARN entries:** $(grep -c '\[WARN\]' logs/app.log || echo '0') 
          - **CRITICAL entries:** $(grep -c '\[CRITICAL\]' logs/app.log || echo '0')
          - **INFO entries:** $(grep -c '\[INFO\]' logs/app.log || echo '0')
          - **DEBUG entries:** $(grep -c '\[DEBUG\]' logs/app.log || echo '0')
          
          ## 🔍 AI Analysis Results
          
          EOF
          
          # Add the analysis results to the job summary
          echo "$ANALYSIS_OUTPUT" >> $GITHUB_STEP_SUMMARY
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*This analysis was automatically generated by GitHub Actions using GitHub Models API*" >> $GITHUB_STEP_SUMMARY